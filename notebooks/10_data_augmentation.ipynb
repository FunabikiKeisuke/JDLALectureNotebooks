{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ集合の拡張（CIFAR10を用いた物体認識）\n",
    "\n",
    "---\n",
    "## 目的\n",
    "畳み込みニューラルネットワーク (Convolutional Neural Network; CNN) を用いてCIFAR10データセットに対する物体認識を行う．\n",
    "その際，データ集合の拡張（Data Augmentation）を行うことで認識性能がどのように変化するかを確認する．\n",
    "\n",
    "## 対応するチャプター\n",
    "* 7.4: データ集合の拡張\n",
    "* 8.1.3: バッチアルゴリズムとミニバッチアルゴリズム\n",
    "* 8.3.1: 確率的勾配降下法\n",
    "* 9.1: 畳み込み処理\n",
    "* 9.3: プーリング\n",
    "\n",
    "## モジュールのインポート\n",
    "プログラムの実行に必要なモジュールをインポートします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUの確認\n",
    "GPUを使用した計算が可能かどうかを確認します．\n",
    "\n",
    "`Use CUDA: True`と表示されれば，GPUを使用した計算をPyTorchで行うことが可能です．\n",
    "Falseとなっている場合は，上記の「Google Colaboratoryの設定確認・変更」に記載している手順にしたがって，設定を変更した後に，モジュールのインポートから始めてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CUDA: True\n"
     ]
    }
   ],
   "source": [
    "# GPUの確認\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('Use CUDA:', use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの読み込み\n",
    "CIFAR10データセットを読み込みます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "train_data = CIFAR10(root=\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_data = CIFAR10(root=\"./\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xgDd3iX2zmSV"
   },
   "source": [
    "## ネットワークモデルの定義\n",
    "畳み込みニューラルネットワークを定義します．\n",
    "\n",
    "ここでは，畳み込み層2層，全結合層3層から構成されるネットワークとします．\n",
    "以前の演習と同じネットワーク構造のため，詳細は割愛します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TNHnp_YczmY3"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.l1 = nn.Linear(8 * 8 * 32, 1024)\n",
    "        self.l2 = nn.Linear(1024, 1024)\n",
    "        self.l3 = nn.Linear(1024, 10)\n",
    "        self.act = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.pool(self.act(self.conv1(x)))\n",
    "        h = self.pool(self.act(self.conv2(h)))\n",
    "        h = h.view(h.size()[0], -1)\n",
    "        h = self.act(self.l1(h))\n",
    "        h = self.act(self.l2(h))\n",
    "        h = self.l3(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cs7zgI0o0KW-"
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像変換によるAugmentation\n",
    "\n",
    "Data Augmentationのための関数を作成します．\n",
    "\n",
    "\n",
    "PyTorchでは，代表的な画像処理（画像変換）によるData Augmentationは，torchvision.transformsとして利用することが可能です．\n",
    "\n",
    "`transforms.Compose`を使用することで，複数の処理を連続して処理して画像データを返すことが可能となります．\n",
    "Composeの引数として，処理を行いたい変換のクラスをリスト内に定義します．\n",
    "今回は以下のものを設定します．\n",
    "\n",
    "* ColorJitter: コントラストや明るさ，色調の変換\n",
    "* RandomCrop: 画像の矩形をランダムに切り取り\n",
    "* RandomHorizontalFlip: 画像をランダムに左右反転\n",
    "* RandomRotation: 画像をランダムに回転\n",
    "* ToTensor: 画像データをPyTorchのTensorオブジェクトへ変換（Augmentationでは無いことに注意）\n",
    "\n",
    "これらの処理をリストに定義し，Composeクラスへ与えることで，定義した処理をランダムに適用したデータを返すことが可能となります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkN9dZVP0KNY"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([transforms.ColorJitter(brightness=0, contrast=0),\n",
    "                                      transforms.RandomCrop(32, padding=1),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomRotation(degrees=(0, 90)),\n",
    "                                      transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MUNa9Xe79vAG"
   },
   "source": [
    "#### 学習\n",
    "\n",
    "上記で定義したData Augmentationを用いて学習を行います．\n",
    "\n",
    "Data Augmentaionを適用するために，CIFAR10データセットを読み込む際に，`transform_transformtrain`の引数に上で定義したComposeを設定します．\n",
    "このようにすることで，データの読み出し時に自動的に画像変換を行いデータを呼び出すことが可能となります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 465062,
     "status": "ok",
     "timestamp": 1562840822239,
     "user": {
      "displayName": "Tsubasa Hirakawa",
      "photoUrl": "https://lh5.googleusercontent.com/-p6Kjr3nd0AU/AAAAAAAAAAI/AAAAAAAAJG0/tCF9JFOo7tk/s64/photo.jpg",
      "userId": "03545166870843244307"
     },
     "user_tz": -540
    },
    "id": "68RE3RTa76-W",
    "outputId": "4a27a489-58d3-4d68-e076-5f50804633ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "epoch: 1, mean loss: 1.9131185606384278, mean accuracy: 19.163682864450127, elapsed_time :19.7551691532135\n",
      "epoch: 2, mean loss: 1.5191717971801757, mean accuracy: 28.877237851662404, elapsed_time :39.543442249298096\n",
      "epoch: 3, mean loss: 1.321909041519165, mean accuracy: 33.67774936061381, elapsed_time :59.32659840583801\n",
      "epoch: 4, mean loss: 1.167084330444336, mean accuracy: 37.21611253196931, elapsed_time :79.1593930721283\n",
      "epoch: 5, mean loss: 1.0465341638183594, mean accuracy: 39.968030690537084, elapsed_time :99.33034944534302\n",
      "epoch: 6, mean loss: 0.9427057851409912, mean accuracy: 42.576726342711, elapsed_time :119.39043092727661\n",
      "epoch: 7, mean loss: 0.8524582386779785, mean accuracy: 44.608695652173914, elapsed_time :139.45860624313354\n",
      "epoch: 8, mean loss: 0.7567504563522339, mean accuracy: 46.65856777493606, elapsed_time :159.51991391181946\n",
      "epoch: 9, mean loss: 0.67154982837677, mean accuracy: 48.64705882352941, elapsed_time :179.27200198173523\n",
      "epoch: 10, mean loss: 0.5897793380737305, mean accuracy: 50.46419437340153, elapsed_time :199.00010514259338\n"
     ]
    }
   ],
   "source": [
    "# ネットワークモデル・最適化手法の設定\n",
    "model = CNN()\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# ミニバッチサイズ・エポック数．学習データ数の設定\n",
    "batch_size = 64\n",
    "epoch_num = 10\n",
    "n_iter = len(train_data) / batch_size\n",
    "\n",
    "# データローダーの設定\n",
    "train_data = CIFAR10(root=\"./\", train=True, transform=transform_train, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 誤差関数の設定\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if use_cuda:\n",
    "    criterion.cuda()\n",
    "\n",
    "# ネットワークを学習モードへ変更\n",
    "model.train()\n",
    "\n",
    "start = time()\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    sum_loss = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for image, label in train_loader:\n",
    "        \n",
    "        if use_cuda:\n",
    "            image = image.cuda()\n",
    "            label = label.cuda()\n",
    "\n",
    "        y = model(image)\n",
    "\n",
    "        loss = criterion(y, label)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "        \n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "        \n",
    "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
    "                                                                                 sum_loss / n_iter,\n",
    "                                                                                 count.item() / len(train_loader),\n",
    "                                                                                 time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "119eIrSmzmw6"
   },
   "source": [
    "#### テスト\n",
    "学習したネットワークモデルを用いて評価を行います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16059,
     "status": "ok",
     "timestamp": 1562814121585,
     "user": {
      "displayName": "Tsubasa Hirakawa",
      "photoUrl": "https://lh5.googleusercontent.com/-p6Kjr3nd0AU/AAAAAAAAAAI/AAAAAAAAJG0/tCF9JFOo7tk/s64/photo.jpg",
      "userId": "03545166870843244307"
     },
     "user_tz": -540
    },
    "id": "yoYVMRGLzm1I",
    "outputId": "066ff9d2-ca10-4c95-aafe-4e6ea3487d73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.6933\n"
     ]
    }
   ],
   "source": [
    "# データローダーの準備\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
    "\n",
    "# ネットワークを評価モードへ変更\n",
    "model.eval()\n",
    "\n",
    "# 評価の実行\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for image, label in test_loader:\n",
    "\n",
    "        if use_cuda:\n",
    "            image = image.cuda()\n",
    "            label = label.cuda()\n",
    "            \n",
    "        y = model(image)\n",
    "\n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "\n",
    "print(\"test accuracy: {}\".format(count.item() / 10000.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomErasing\n",
    "\n",
    "その他のAugmentationとして，Random Erasing [1] があります．\n",
    "\n",
    "Random Erasingは，画像の一部にランダムに矩形を設定しマスク処理を行うData Augmentationです．\n",
    "\n",
    "RandomErasingもtorchvision.transformsに実装されていますので，これを使用してその効果を確認します．\n",
    "先ほどと同様に，Composeを使用し，その引数として，ToTensorとRandomErasingを定義します．\n",
    "\n",
    "![](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/143078/02489e6c-9489-4e69-c7c1-7a02bf341c08.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.RandomErasing()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習\n",
    "\n",
    "RandomErasingを用いてネットワークの学習を行います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "epoch: 1, mean loss: 1.9754568670654298, mean accuracy: 17.452685421994886, elapsed_time :19.70690131187439\n",
      "epoch: 2, mean loss: 1.549193876953125, mean accuracy: 28.32097186700767, elapsed_time :39.48051834106445\n",
      "epoch: 3, mean loss: 1.3385136457824707, mean accuracy: 33.05754475703325, elapsed_time :59.26152491569519\n",
      "epoch: 4, mean loss: 1.1728572580718994, mean accuracy: 37.089514066496164, elapsed_time :78.9121642112732\n",
      "epoch: 5, mean loss: 1.059196215362549, mean accuracy: 39.69437340153453, elapsed_time :98.5942051410675\n",
      "epoch: 6, mean loss: 0.9557376274871826, mean accuracy: 42.20716112531969, elapsed_time :118.32133793830872\n",
      "epoch: 7, mean loss: 0.8569230896759034, mean accuracy: 44.53964194373402, elapsed_time :138.05909371376038\n",
      "epoch: 8, mean loss: 0.7680867225265503, mean accuracy: 46.570332480818415, elapsed_time :157.92166018486023\n",
      "epoch: 9, mean loss: 0.6832865827941894, mean accuracy: 48.589514066496164, elapsed_time :178.2521095275879\n",
      "epoch: 10, mean loss: 0.5938332232666016, mean accuracy: 50.62276214833759, elapsed_time :198.11130285263062\n"
     ]
    }
   ],
   "source": [
    "# ネットワークモデル・最適化手法の設定\n",
    "model = CNN()\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# ミニバッチサイズ・エポック数．学習データ数の設定\n",
    "batch_size = 64\n",
    "epoch_num = 10\n",
    "n_iter = len(train_data) / batch_size\n",
    "\n",
    "# データローダーの設定\n",
    "train_data = CIFAR10(root=\"./\", train=True, transform=transform_train, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 誤差関数の設定\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if use_cuda:\n",
    "    criterion.cuda()\n",
    "\n",
    "# ネットワークを学習モードへ変更\n",
    "model.train()\n",
    "\n",
    "start = time()\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    sum_loss = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for image, label in train_loader:\n",
    "        \n",
    "        if use_cuda:\n",
    "            image = image.cuda()\n",
    "            label = label.cuda()\n",
    "\n",
    "        y = model(image)\n",
    "\n",
    "        loss = criterion(y, label)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "        \n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "        \n",
    "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
    "                                                                                 sum_loss / n_iter,\n",
    "                                                                                 count.item() / len(train_loader),\n",
    "                                                                                 time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダーの準備\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
    "\n",
    "# ネットワークを評価モードへ変更\n",
    "model.eval()\n",
    "\n",
    "# 評価の実行\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for image, label in test_loader:\n",
    "\n",
    "        if use_cuda:\n",
    "            image = image.cuda()\n",
    "            label = label.cuda()\n",
    "            \n",
    "        y = model(image)\n",
    "\n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "\n",
    "print(\"test accuracy: {}\".format(count.item() / 10000.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixup\n",
    "\n",
    "その他の近年提案された効果的なAugmentation手法として，Mixup [2] があります．\n",
    "\n",
    "Mixupは二つの画像とそのラベル$(x_i, y_i), (x_j, y_j)$を下の式に従い，一定の比率で設計保管することで，中間的なデータを作成する手法です．\n",
    "\n",
    "\n",
    "$$\\tilde{x} = \\lambda x_i + (1 - \\lambda) x_j$$\n",
    "$$\\tilde{y} = \\lambda y_i + (1 - \\lambda) y_j$$\n",
    "\n",
    "\n",
    "![](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/143078/048f8b50-f277-7b60-e16b-99c67ae19873.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習\n",
    "\n",
    "Mixupを用いてネットワークの学習を行います．\n",
    "\n",
    "まず，ベータ分布からmixupの割合`lam`をサンプリングし決定します．\n",
    "\n",
    "そして，ミニバッチのサンプルを読み込んだのちに，ミニバッチ内の画像データの順番をランダムに入れ替えた`image_rand`を作成し，元の順番のミニバッチとの重みつき和を計算することでデータのmixupを行います．\n",
    "\n",
    "また，教師ラベルに対しても同様の処理を行います．\n",
    "この時，ラベルを一度one-hotベクトル表現のラベルに変換したのちに，そのベクトルの重みつき和を求めることで，ラベルのmixupをおこんばいます．\n",
    "\n",
    "lossの計算時は，クラスインデックスを引数に与える通常のクロスエントロピー誤差（`nn.CrossEntropyLoss()`）を使用することができないため，ネットワークの出力とベクトル表現のラベルからクロスエントロピーを手動で計算します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ネットワークモデル・最適化手法の設定\n",
    "model = CNN()\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# ミニバッチサイズ・エポック数．学習データ数の設定\n",
    "batch_size = 64\n",
    "epoch_num = 10\n",
    "n_iter = len(train_data) / batch_size\n",
    "\n",
    "# データローダーの設定\n",
    "train_data = CIFAR10(root=\"./\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# ネットワークを学習モードへ変更\n",
    "model.train()\n",
    "\n",
    "start = time()\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    sum_loss = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for image, label in train_loader:\n",
    "        \n",
    "        # mix up -------------------------------------------\n",
    "        b = image.size(0)\n",
    "        lam = np.random.beta(1, 1)\n",
    "            \n",
    "        rand_idx = torch.randperm(b)\n",
    "        image_rand = image[rand_idx]\n",
    "        mixed_image = lam * image + (1 - lam) * image_rand\n",
    "            \n",
    "        onehot = torch.eye(10)[label]\n",
    "        onehot_rand = onehot[rand_idx]\n",
    "        mixed_label = lam * onehot + (1 - lam) * onehot_rand\n",
    "        # --------------------------------------------------\n",
    "        \n",
    "        if use_cuda:\n",
    "            mixed_image = mixed_image.cuda()\n",
    "            mixed_label = mixed_label.cuda()\n",
    "        \n",
    "        y = model(mixed_image)\n",
    "    \n",
    "        b, c = y.shape\n",
    "        log_softmax = torch.log_softmax(y, dim=1)\n",
    "        loss = - torch.sum(mixed_label * log_softmax) / b\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "        \n",
    "    print(\"epoch: {}, mean loss: {}, elapsed_time :{}\".format(epoch, sum_loss / n_iter, time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダーの準備\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
    "\n",
    "# ネットワークを評価モードへ変更\n",
    "model.eval()\n",
    "\n",
    "# 評価の実行\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for image, label in test_loader:\n",
    "\n",
    "        if use_cuda:\n",
    "            image = image.cuda()\n",
    "            label = label.cuda()\n",
    "            \n",
    "        y = model(image)\n",
    "\n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "\n",
    "print(\"test accuracy: {}\".format(count.item() / 10000.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題\n",
    "1. 使用するAugmentationを変更して精度の変化を確認しましょう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "1. Z. Zhong, et al., \"Random Erasing Data Augmentation,\" in AAAI, 2020.\n",
    "2. H. Zhang, et al., \"mixup: BEYOND EMPIRICAL RISK MINIMIZATION,\" in ICLR, 2018."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
